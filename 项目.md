# 项目

## Android项目

## 技术栈：MVVM模式+Android KTX

Android是一组Kotlin扩展程序，属于jetpack系列，提供向后兼容性

基于Google OpenVpn接口调用api函数完成隧道模块的组建：设置通道口tun0（port，IP）

### 项目职责

1.负责应用场景设计，调查环境配置等系列系统调配设置
2.需求理解
3.模块设计
4.与组员共同完成开发
5.交付

### 难点

1. 应用场景过程：学校的网络地址是内网IP，前期考虑到应用场景，需要在外网的情况下访问内网，因此找了台机器用手机热点进行链接网络，用内网的机器搭了一个服务器，设置好了IP地址之后，发现仍然无法进行地址通信，研究了三天发现了两个问题，第一个是因为建立隧道的时候客户端在连接的时候端口号没有改为61195，第二个是因为客户端Ip地址本身跟手机一样处于自身局域网，无法访问到ip地址在重邮内网的服务器，因此设置了一个NAT，把内网服务器中设置了一个NAT，这样就可以直接访问然后模拟传输过程了，VPN要具有转发的功能，就是用自身去代替NAT的这个过程，但是如果没有使用VPN，就无法访问到内网
2. 组件开发：检查版本号-开始连接-建立通道-等待包传递-验证成功-建立成功，检查版本号到建立通道这个流程是我做的，首先点击botton按钮之后会启动主线程，再检查状态标签，就是是否处于连接的状态，如果否那就进行打开服务，获取客户端的IP地址，默认端口，再将硬件地址这些一起打包放进一个List






## Spring项目

技术栈：`Spring boot+Redis+Spring security +Thymeleaf`

1.通过对登录用户颁发登录凭证，将登陆凭证存进 Redis 中来记录登录用户登录状态，使用拦截器进行登录状态检查，使用 Spring Security 实现权限控制，解决了 http 无状态带来的缺陷，保护需登录或权限才能使用的特定资源。
2.针对每个浏览器也就是多个线程操作同个单例bean也就是获取seesion中的user信息的线程安全问题（不用cookie，session存储user信息，分布式部署存在Session共享的问题）使用 ThreadLocal 在当前线程中存储用户数据，代替 session 的功能便于分布式部署，当用户登录后，会将用户信息存入Token中返回前端，当用户调用需要授权的接口时，需要在header中携带 Token，然后拦截器中解析Token，获取用户信息，调用自定义的类(AuthNHolder)存入ThreadLocal中，当请求结束的时候，将ThreadLocal存储数据清空， 中间的过程无需在关注如何获取用户信息，只需要使用工具类的get方法即可。

使用set将线程作为key，要保存的bean为value存储到一个map当中。在拦截器的 preHandle 中存储用户数据并构建用户认证的结果存入 SecurityContext，在 postHandle 中将用户数据存入 Model，在 afterCompletion 中清理用户数据。
3.使用 Redis 的集合List数据类型来解决踩赞、相互关注功能，（采用事务管理，保证数据的正确，采用“先更新数据库，再删除缓存”策略保证数据库与缓存数据的一致性。）采用 Redis 存储验证码，解决性能问题和分布式部署时的验证码需求。采用 Redis 的 HyperLogLog 存储每日 UV、Bitmap 存储 DAU，实现网站数据统计的需求。
4.使用 Kafka 作为消息队列，利用高并发、高吞吐量、消息持久化的特点存储点赞以及喜欢两种业务功能的topic，用户被点赞、评论、关注后以系统通知的方式推送给用户，用户发布或删除帖子后向 elasticsearch 同步，wk 生成长图后将长图上传至云服务器，对系统进行解耦、削峰。
5.使用 elasticsearch + ik 分词插件实现全局搜索功能，当用户发布、修改或删除帖子时，使用 Kafka 消息队列异步将帖子给 elasticsearch 同步。
6.使用分布式定时任务 Quartz 定时计算帖子分数，来实现热帖排行的业务功能。
7.对频繁需要访问的数据，如用户信息、帖子总数、热帖的单页帖子列表，使用 Caffeine 本地缓存 + Redis 分布式缓存的多级缓存，提高服务器性能，实现系统的高可用。

Spring Email：

Spring  security:授权

AOP：统一处理日志，统一处理系统需求，将定义好的系统错误日志定义放入到额外的bean中，切点在service包下的所有类的所有方法的所有参数设置，使用before标签前置通知.

性能：`Redis`做统计、缓存，Caffeine二级缓存

高并发通过kafka实现.

### Kafka

生产者与消费者模式，高性能的特性：分布式的分区特性、ISR数据同步，高效利用磁盘、宏观架构

磁盘的顺序读写，message是不断追加到本地磁盘文件末尾的，可以使用mmap将磁盘数据缓存到内存当中，通过修改内存直接修改磁盘文件（利用操作系统page来实现映射）。

`Kafka`

```
public class Event{
  privite String topic;
  privite int userId;
  privite int entityId;
  privite Map<String, Integer> date=new HashMap<>();
}

EventConsumer:
@kafkaListener(topic={TOPIC_COMMENT,...})
public void handleMessage(ConsumerRecord record){
  Event event=JSONObeject.parseObeject(record.value().toString(),Event.class);
  if(event==null){
    //记录日志(查看日志:)
    return;
  }
  Message message=new Message();
  message.setToldId();setFromId;setConversationId(event.getTopic());
  Map<String,Integer> content=new HashMap<>();
  content.put("userId",event.getUserID());
  if(!event.getData().isEmpty()){
    for(Map.Entry<String,Obeject> entry : event.getData().EntrySet()){
      content.put(entry.getKey(),entry.getValue());
    }
   }
  message.setContent(JSONObeject.ToJSONString(content));
  messageService.addMessage(message);
}
EventProducer:
public void fireEvent(Event event){
	//发布事件
	kafkaTemplate.send(event.getTopic(),JSONObeject.ToJSONString(event));
  
}
```

### Elasticsearch

 

### Zookeeper

数据模型整体看成一棵树，每个节点称为ZNode，具有唯一标识用于协调服务

基于观察者模式设计，主要存储和管理数据接收观察者的注册.

### RabbitMQ

分布式系统broker，主备模式，镜像节点不负责读写，吞吐量低时可以选择.

### 

### 问题解决

1.Redis的**SetNX分布式锁**保证点赞功能的原子性，考虑在Redis存储两个键值对，点赞将set集合中加入点赞的用户，被点赞的用户赞数加1，那么在多个用户的不同线程请求下，为了不影响单独业务插入其他的命令执行，则需要考虑线程安全的问题，SetEx的方法缺乏原子性，则需要在删除锁的步骤中判断删除的锁必须是添加锁的对象，用一个uuid进行条件判断，但此时还是不能保证自己锁和删除锁的原子性，于是采用**lua脚本**确保删除脚本的原子性。

2.Elasticsearch6.x 与 Redis 启动冲突问题

SpringBoot 的 spring-boot-starter-data-redis 默认是以 lettuce 作为连接池的， 而在 lettuce，elasticsearch transport 中都会依赖 netty, 二者的 netty 版本不一致，不能够兼容。NettyRuntime 类中有下面的方法，启动的时候 Redis 和 ElasticSearch 都会调用，然后就会报下面绿字错误。即 Redis 先设置好了 availableProcessors 处理器，es 又来设置，系统就会认为重复了，就不会启动。

解决办法：es调用setAvilableProcessors（）中初始化availableProcessors时有个If判断语句，判断其如果不为0就会抛出异常，而Redis已经初始化过了，es就会报错，可以设置es的依赖netty.runtime.available.processors初始值为false，或者直接升级es7.

3.搜索功能：ES与Kafka的帖子同步，ES异步请求

使用kafka创建一个Topic，帖子的相关信息将被发布到这个topic中，Kafka生产者就会将新发布的信息发送到topic中。Kafka消费者接收到新帖子消息时，是将帖子相关信息转换为JSon格式作为Es的索引文档，并同步到Es中。

**优化：** 同时设置一个定时任务来定期检查数据库中的帖子是否将新帖子同步到Es中----ScheduledExecutorService/Kafka的消息队列确保只有一个消费者来进行完成定时任务

访问数据库业务可以使用canal组件+Binlog文件设置为row模式，确保回滚数据库操作.

分布式锁除了SetNX+Lua脚本释放锁之外还可以使用Zk的临时性结点，将业务访问装填至节点头，只有一个获得锁的节点来执行任务结束时释放掉临时性结点。

4.登录验证码：

使用Kaptcha生成验证码，用一个String类型的KaptchaOwner保存并放入客户端cookie、Redis存储中（redisTemplate.opsForValue().set）,登录方法中首先在Redis里取一个ticket，这个ticket保存了登陆凭证，每次都要查询用户的登陆凭证

5.关注、取消关注（事务功能）

使用zset数据类型存储数据：

6.评论、点赞、关注的系统通知组件：

Producer:fireEvent（）方法发送Event

调用KafkaTemplate.send(event.getTopic(),JSONObject.)

Consumer:三个消费者主题用注解@kafkaListener->参数ConsumerRecord的value值保存消息的JSON格式->`用event保存JSON还原的Object对象（record.value().toString(),Event.class）`->用一个Map存储事件触发时的Message，map对象用于保存事件发起方ID，事件的内容，事件的ID->设置好message的JSON实体->`messageService.addMessage(message)`

7.Caffeine二级缓存：

用`loadingCache<> cache=Caffenine.newBuileder()`

8.热门帖子：

计算帖子分数set中存储（去重）`redisTemplate.boundSetOps(redisKey)`

### 单元测试

`Spring-boot-starter-test:Junit、Spring Test、AssertJ...`

`@BeforeAll/@AfterAll `在每个测试类前调用，只调用一次，初始化一个用户初始数据/操作数据库数据，更新用户数据，把数据状态调成2，使数据失效

`用@Test注解判断断言与查询到的数据是否一样 Assert.assertEquals（expected,实际值,delta精度）设置期望值和实际值`

`@BeforeEach @AfterEach`每一个测试类都要调用一次

1.理解需求
2.设计系统流程
3.组员开发模块
4.完成开发

### Jmeter压力测试/单接口负载测试 聚合报告

使用Jmeter观察总的tps，控制5%的接口调用比例

测试夹具

### 测试经历的ＢＵＧ

1.自己使用的时候：在第一次使用Jmeter测试一个get功能请求的时候，直提示错误的请求key报错，没有一一核对路径名、参数名跟请求参数，扫了一眼都没有错误，就盲目向上提交错误，还好最后是由导师来进行核实，发现参数名末尾复制的时候有一个空格导致的错误，如果反馈提交给项目组可能会给后端人员造成不必要的麻烦.

2.

### 对测开的理解／为什么要做测开

从一个产品流程来看，可能会被简单的认为先产品评审，开发后测试，但实际上三者是线性关系，三者在评审阶段都需要在场，实际上测开工程师还是围绕业务展开，都是为了更好更快的测试提交，从产品需求评审到上线整个周期的质量保证，测试都是为了保障产品的质量，对于对应的ｂｕｇ要做到修复验证并进行原因分析归类，如果遇到不通过的，需要将ＢＵＧ提交给开发处理，在发布产品之后，测开工程师需要跟进线上回归，

### 实习遇到的问题 

### 实习职责

1.产品经理收集信息制定需求，对方案进行评审，我们就开始写测试计划，包括每一个时间节点的安排：测试进度->测试需要用的人力->账号，数据等；然后对ui设计进行评审，就会交付给开发（开发写开发方案，**评审**->测试组会提一些意见，执行开发）->交付给测试组，我们先熟悉需求然后写测试用例，之后就开需求评审会，讨论测试用例的覆盖广度，之后就会挑核心用例当作冒烟测试，开发通过以后会备注checklists（需要安全审计、性能等等），测试接管该需求，进行用例执行阶段，查询bug，提交，一轮测试结束就开始第二轮验收第一轮的bug，直到没有bug，通过之后开始接下一个需求。

2.回归测试，每一个月一个版本更新，最后三天进行对整个web网站的测试，用例是之前选出来的最核心的功能，或者是容易发生BUG的测试点，也会执行几轮，然后就是内测也就是alpha测试，让员工先使用常见功能，一天之后进行beta测试，达到预设推送人数后，会观察异常搜集平台是否有异常和bug，如果没有就上线。

１.负责德赛库房服务端平台各项测试，主要使用selenium参与一个web用户管理项目的自动化测试，功能包括用户登录，用户管理，签到打卡列表用户导出(list 保存一组复选框元素最后导出的操作)，个人中心提交报告（悬停Actions.clickandhold().perform(),），使用Junit完成库房入库、出库的库存数量输出正确与否的单元测试。

2.我们组负责库房用户端的用户功能模块开发，包括用户登录用户搜索用户查询一些登录信息基础服务，然后针对浏览器多线程调用单例bean采用的做法是用户登入之后信息存入token中返回前端，当用户调用需要授权的接口时，需要在header中携带 Token，然后拦截器中解析Token，获取用户信息，调用自定义的类(AuthNHolder)存入ThreadLocal中，当请求结束的时候，将ThreadLocal存储数据清空， 中间的过程无需在关注如何获取用户信息，只需要使用工具类的get方法即可。使用set将线程作为key，要保存的bean为value存储到一个map当中。

3.我们库房系统之前使用也是比较老了，之前因为是面向几个部门的，然后需要把库房系统跟大厅用户系统进行整合，所以数据库前端后端的东西都需要进行重做，我们组参与了需求分析，表设计，新系统ui的设计，还有用户登录模块的设计，用户登录模块功能测试以及接口测试，由于整个业务需要去面向整个公司，有需求是对用户做鉴权处理，也就是谁做了出库操作会有一个操作人的记录，之前的登录账号由于只有两个管理员账号，因为库房只设置了两个窗口，我们现在会可以通过自己的账号进行云平台登录操作，并且也能看到库房的一个表单，但是无法进行入库出库操作，只有获得了鉴权码，才能进行操作，但我们基本使用的是组长的账号。

3.负责项目交付，与开发人员交流需求设计测试用例两百余条，完成项目的功能测试；  

### 设计测试用例

论坛是一个允许用户发布帖子、回复帖子以及交流讨论的平台。以下是一些可能的论坛设计测试用例：

1. 用户注册和登录：
   - 测试用户注册功能，验证是否能成功注册新用户。
   - 测试用户登录功能，验证是否能使用正确的用户名和密码登录。
   - 测试使用错误的用户名或密码登录，验证是否能正确处理登录失败情况。
   - 测试登录后是否正确显示用户信息和登录状态。

2. 发布帖子：
   - 测试用户发布帖子功能，验证是否能成功发布帖子并显示在论坛列表中。
   - 测试发帖时是否能正确处理标题和内容为空或过长的情况。

3. 回复帖子：
   - 测试用户回复帖子功能，验证是否能成功回复帖子并显示在帖子详情中。
   - 测试回复帖子时是否能正确处理内容为空或过长的情况。

4. 帖子列表和排序：
   - 测试论坛首页是否正确显示最新的帖子列表。
   - 测试帖子列表是否能按照最新时间或热度进行排序。
   - 测试论坛的分页功能是否正确显示帖子列表，并能正确跳转到指定页码。

5. 帖子详情和回复列表：
   - 测试点击帖子标题后是否能正确跳转到帖子详情页面。
   - 测试帖子详情页面是否正确显示帖子内容和回复列表。
   - 测试回复列表是否能按照最新时间排序，并能正确分页显示。

6. 权限控制：
   - 测试未登录用户是否能访问发帖和回复功能，应该验证是否正确提示登录。
   - 测试非帖子作者是否能修改或删除帖子和回复，应该验证是否有权限限制。

7. 编辑和删除功能：
   - 测试用户是否能编辑自己发布的帖子和回复，验证是否能正确保存修改。
   - 测试用户是否能删除自己发布的帖子和回复，验证是否能正确删除。

8. 网页样式和布局：
   - 测试论坛的网页样式和布局在不同浏览器和设备上是否正确显示。
   - 测试响应式布局在不同屏幕尺寸下是否适配良好。

9. 安全性测试：
   - 测试是否存在帖子内容注入或脚本注入漏洞。
   - 测试是否存在跨站脚本攻击（XSS）或跨站请求伪造（CSRF）漏洞。

10. 并发测试：
  - 测试多个用户同时发帖和回复的场景，验证是否能正确处理并发请求。
