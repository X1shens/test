面试官你好，我叫曾文希，来自快手商业化，目前主要负责的是内循环-激励广告业务，日常的工作主要涉及需求迭代交付-测试提效-横向质量保障-大模型应用探索四个方面；

整体的测试工作收口在商业化C端赚钱页任务金币玩法和IAA、IAP等内容消费中的广告入口，上下游涉及主站用增、商业化引擎、风控、电商和一些内容消费业务，广告服务水位线晚高峰量级在百万左右，25年的本身迭代需求加上外部业务需求提需大概350+，个人承接比例40%左右

去年的工作在横向上 主要作为流量回放接口同学，主推流量回放接入CI/CD流程，整体覆盖商业化10余个FT-P0/P1接口60%，解决流量回放落地激励业务中，平台对业务影响的卡点，同时拉齐平台和接入同学根据接入SOP遇到的卡点问题，去年解决大组问题15例；【遇到的问题，怎么推动，卡点】

在大促节点上，比如双11，618，cny这些活动节点，我们会通过服务加固、压测、故障演练等措施进行服务保障

在模型上的做功探索主要是for流量回放的提效和提升业务的接入率，契机是6月公司一个的AI挑战赛，流量回放平台出的一个diff归因排查的问题，这边个人比较感兴趣所以落地的一个公司二等奖的项目，然后目前是正在对两条业务线试点试用，后续打算推广至平台大范围使用的一个大模型工具；

# 激励广告业务

## 背景

激励业务主要收口在主站赚钱页里的商业化分水任务中，里面所有任务涉及到的商业化广告及样式都由我们负责，还有自建、共建信息流里的激励广告位也由我们维护，业务范围涉及广告样式、权益发放【短视频/直播深浅度金币发放、内容消费的转化-短剧发奖金币/剧集、游戏道具发放、小说免广权益等】、计费转化【广告点击曝光、金币发放、广告成本转化】等

## 印象深刻的问题

## 面临的问题

外部

一直以来都在围绕提升质效和丰富测试质量保障手段来做功。

trace能力较弱。激励是个广告投放链路下游的C端业务，测试手段上更依赖手工测试，虽然目前已经接入流量回放，但对于服务端的发现问题手段更多是通过端上触发真实请求，以端样式/协议生效为第一体感，重放请求通过arthas定位来定位服务端代码行，整体对于研发来说比较靠经验，修复bug时间长短不一，整体的trace能力依靠测试环境采样率，线上问题回捞依靠客户端日志；

线上数据构造较难。特别涉及到投放链路的上游改动时，在我们测试过程当中非常依赖上游广告平台的实时性广告投放，遇到一些广告主新业务链路时，会面临广告投放链路长导致广告失效快，经过引擎粗排精排后的召回失败等问题让测试无法体验到对应的广告；

手工召回问题的有限。依托手工测试，在面临迭代任务繁重的问题时，人工难免可能露出的边界case都有可能成为线上问题的来源，激励也在面临羊毛党和黑灰产的挑战，可能只有一例客诉但它可能带来的亏损也是不可想象的。

 内部

人力不足导致的基建缺失，这个业务是23年变动后从引擎拆下来的业务，虚线和+1都是新接手的，24年只有两个正职+外包的人力，目前是一个正职+3个外包的配置，所以之前的一些可复用的基建都未交接过包括所有自动化手段；

目前的一个阶段是在解决去年因客户端原因导致的线上问题，打算补全ui自动化；

## 如何解决

外部

服务trace能力这块主要依赖公司平台继承的服务容器管理平台，但没有一个对应公司级的服务trace链路测试平台，仅各个业务自行开发，激励是一个人力偏新的业务，整体没有对这块的建设；但怎么建设应该也是有方法的，比如对于测试环境，在流量入口添加一个traceId，全链路去透传traceId，在业务日志中添加对应的监控；

构造数据难，链路长这种强合作性的问题只能依靠在项目对齐时就抛出的问题，在整体项目对齐showcase、提测、联调测试的时间节点时，就将这种上下游问题抛出，让上游在测试介入前就准备好测试数据。

第三个召回问题，这种我们目前的一个想法是追齐我们对发奖链路的质量监控，主要是对用户发放的每一笔金币，根据用户的风控行为进行规则校验，来判断对用户的发奖状态行为的可控监控提示，后续可以发展成一个用户行为监控大盘，来提升线上用户行为可控性。

内部

这块对于我来说没有一个比较合适的解法，也不止一次说过人力不足的问题了。

# 流量回放

## 背景

## 怎么推动

## 问题及卡点

# 精准回放

## 背景

## 落地过程

## 遇到的问题及卡点

# 压测

## 压测遇到的问题

## 写链路压测遇到的问题

# 大模型应用

## 背景

## 遇到的问题

## 后续规划
